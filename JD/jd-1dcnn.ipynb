{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import data_preprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据划分为训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = data_preprocess.tensorFromData()\n",
    "trainDataSet = data_preprocess.TextDataSet(X_train, Y_train)\n",
    "testDataSet = data_preprocess.TextDataSet(X_test, Y_test)\n",
    "trainDataLoader = DataLoader(trainDataSet, batch_size=16, shuffle=True)\n",
    "testDataLoader = DataLoader(testDataSet, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取字典\n",
    "word_to_inx, inx_to_word = data_preprocess.get_dic()\n",
    "len_dic = len(word_to_inx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "MAXLEN = 64\n",
    "input_dim = MAXLEN\n",
    "emb_dim = 128\n",
    "num_epoches = 20\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "#     一维卷积带来的问题是需要通过设计不同 kernel_size 的 filter 获取不同宽度的视野。\n",
    "\n",
    "class TextCNN_model(nn.Module):\n",
    "    def __init__(self,len_dic,emb_dim,input_dim):\n",
    "        super(TextCNN_model,self).__init__()\n",
    "        self.embed=nn.Embedding(len_dic,emb_dim)#b,64序列长,128词向量长度\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv1d(input_dim,256,1,1,padding=0),#b,256,128\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2,2)#b,256,64池化窗口2*2，st->/2，step=2\n",
    "        )\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv1d(input_dim,256,3,1,padding=1),#b,256,128\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2,2)#b,256,64\n",
    "        )\n",
    "        self.conv3=nn.Sequential(\n",
    "            nn.Conv1d(input_dim,256,5,1,padding=2),#b,256,128\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool1d(2,2)#b,256,64\n",
    "        )\n",
    "        #b,256,64+64+64\n",
    "        #b,256*192\n",
    "        self.drop=nn.Dropout(0.2)#b,256*192\n",
    "        self.classify=nn.Linear(256*192,3)#b,3  feature_size * window_sizes\n",
    "    def forward(self, x):\n",
    "        x=self.embed(x)\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x3=self.conv3(x)\n",
    "        x=torch.cat((x1,x2,x3),2)\n",
    "        b,c,d=x.size()\n",
    "        x=x.view(-1,c*d)\n",
    "        x=self.drop(x)\n",
    "        out=self.classify(x)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
